{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d815abc-831a-44b1-8fd1-dc99e9d65650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0b81343c-6a6b-4e7e-b07c-1a636591bb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "column_names = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species']\n",
    "\n",
    "df = pd.read_csv('iris.csv', header=None ,names=column_names)\n",
    "numeric_columns = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
    "\n",
    "df[numeric_columns] = df[numeric_columns].apply(pd.to_numeric, errors='coerce')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d231d986-0c20-4fbb-a36e-23abd2fc5d02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3            4\n",
       "0  5.1  3.5  1.4  0.2  Iris-setosa\n",
       "1  4.9  3.0  1.4  0.2  Iris-setosa\n",
       "2  4.7  3.2  1.3  0.2  Iris-setosa\n",
       "3  4.6  3.1  1.5  0.2  Iris-setosa\n",
       "4  5.0  3.6  1.4  0.2  Iris-setosa"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7351f97d-a2d8-4c3d-8c58-9d4f7ef20573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1    2    3               4\n",
       "145  6.7  3.0  5.2  2.3  Iris-virginica\n",
       "146  6.3  2.5  5.0  1.9  Iris-virginica\n",
       "147  6.5  3.0  5.2  2.0  Iris-virginica\n",
       "148  6.2  3.4  5.4  2.3  Iris-virginica\n",
       "149  5.9  3.0  5.1  1.8  Iris-virginica"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "45d690dc-3f56-41a5-b2e5-a67c9ccd08ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       150 non-null    float64\n",
      " 1   1       150 non-null    float64\n",
      " 2   2       150 non-null    float64\n",
      " 3   3       150 non-null    float64\n",
      " 4   4       150 non-null    object \n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 6.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "890a698f-8395-4a68-8022-2b2960f742c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0      1      2      3      4\n",
       "0    False  False  False  False  False\n",
       "1    False  False  False  False  False\n",
       "2    False  False  False  False  False\n",
       "3    False  False  False  False  False\n",
       "4    False  False  False  False  False\n",
       "..     ...    ...    ...    ...    ...\n",
       "145  False  False  False  False  False\n",
       "146  False  False  False  False  False\n",
       "147  False  False  False  False  False\n",
       "148  False  False  False  False  False\n",
       "149  False  False  False  False  False\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1ceb55a5-7237-4314-875d-94ef3e94fc3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    float64\n",
       "1    float64\n",
       "2    float64\n",
       "3    float64\n",
       "4     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc6a982-6434-4583-b5d9-da22a303b304",
   "metadata": {},
   "outputs": [],
   "source": [
    "Как загрузить CSV-файл в Pandas DataFrame?\n",
    "\n",
    "Используя функцию pd.read_csv('filename.csv'), вы можете загрузить данные из CSV-файла в DataFrame.\n",
    "Какую информацию предоставляет функция info() о датасете?\n",
    "\n",
    "Она показывает количество записей, количество не-нулевых значений в каждом столбце, типы данных столбцов и объем памяти, занимаемый DataFrame.\n",
    "Как можно выявить пропущенные значения в датасете?\n",
    "\n",
    "С помощью df.isnull().sum(), которая покажет количество пропущенных значений в каждом столбце."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb02763-01a6-4420-8a52-e34c0e426587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3add2743-dcce-4554-967b-2545f45bfc78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sepal_length    0\n",
       "sepal_width     0\n",
       "petal_length    0\n",
       "petal_width     0\n",
       "species         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f2b0d48f-b116-49d1-a712-561779930e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Пропущенные значения после обработки:\n",
      "sepal_length    0\n",
      "sepal_width     0\n",
      "petal_length    0\n",
      "petal_width     0\n",
      "species         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# df[numeric_columns] = df[numeric_columns].fillna(df[numeric_columns].mean())\n",
    "\n",
    "df_numeric = df[numeric_columns].fillna(df[numeric_columns].median())\n",
    "\n",
    "# df[numeric_columns] = df[numeric_columns].fillna(df[0]\n",
    "\n",
    "\n",
    "print(\"\\nПропущенные значения после обработки:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d95d2867-849b-4a3a-9f8e-fd323623f321",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[numeric_columns] = df[numeric_columns].ffill()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c115f2b-78af-486a-8d29-fa27c80958ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "Какую стратегию вы использовали для обработки пропущенных значений и почему?\n",
    "\n",
    "Выбор стратегии зависит от природы данных и контекста задачи. Например, если количество пропущенных значений невелико, удаление строк может быть приемлемым. Если пропущенные данные существенны, заполнение средним или медианой может сохранить целостность данных.\n",
    "Как заполнение пропущенных значений повлияло на датасет?\n",
    "\n",
    "Заполнение может изменить распределение данных и повлиять на статистические свойства столбцов. Важно оценить влияние перед тем, как продолжать анализ.\n",
    "Когда может быть более целесообразно удалить строки с пропущенными значениями, вместо их заполнения?\n",
    "\n",
    "Когда количество пропущенных значений невелико относительно общего объема данных или когда заполнение может привести к искажению данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc0e651-4b10-409b-9b74-066b8841deae",
   "metadata": {},
   "outputs": [],
   "source": [
    "Exercise 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8a37b523-dcef-40a6-adff-517e108667c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "df_scaled = scaler.fit_transform(df_numeric)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6625263b-98e8-4527-8d91-d0f0bbcb46e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "# scaler = StandardScaler()\n",
    "# df_standardized = scaler.fit_transform(df_numeric)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "57c5b8c3-f3c8-4264-a4a1-4526a9f738bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded = pd.get_dummies(df['species'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a004cd69-238f-4f90-b7ea-9af2bca15ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sepal_length sepal_length_binned\n",
      "140           6.7              Medium\n",
      "141           6.9                Long\n",
      "142           5.8              Medium\n",
      "143           6.8                Long\n",
      "144           6.7              Medium\n",
      "145           6.7              Medium\n",
      "146           6.3              Medium\n",
      "147           6.5              Medium\n",
      "148           6.2              Medium\n",
      "149           5.9              Medium\n"
     ]
    }
   ],
   "source": [
    "df['sepal_length_binned'] = pd.cut(df['sepal_length'], bins=3, labels=['Short', 'Medium', 'Long'])\n",
    "print(df[['sepal_length', 'sepal_length_binned']].tail(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "52edab4d-0e7e-441a-aa53-eb06924dbca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Questions:\n",
    "\n",
    "В чем разница между нормализацией и стандартизацией?\n",
    "\n",
    "Нормализация (Min-Max масштабирование): Преобразует данные в заданный диапазон (обычно от 0 до 1).\n",
    "Стандартизация (Z-score): Преобразует данные так, что они имеют среднее 0 и стандартное отклонение 1.\n",
    "Как one-hot кодирование трансформирует категориальные переменные?\n",
    "\n",
    "Преобразует категориальные переменные в набор бинарных столбцов, где каждый столбец соответствует одной категории, и значение 1 указывает на принадлежность к этой категории.\n",
    "Почему может потребоваться бининг непрерывных переменных в категории?\n",
    "\n",
    "Для упрощения модели, уменьшения чувствительности к выбросам или для использования алгоритмов, требующих категориальных данных.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa744140-4f2a-4baf-bcdf-39bade49db47",
   "metadata": {},
   "outputs": [],
   "source": [
    "Exercise 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a4760315-90df-4123-b261-e35a56f0c64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['petal_area'] = df['petal_length'] * df['petal_width']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cff2b1-fc80-4c8e-8052-cde8b0487c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thre is no any datasets that related with datetime!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "8cfa000b-c90a-498f-992e-ecc87583af7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['petal_ratio'] = df['petal_length'] / df['petal_width']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb71d01-c901-4c39-8727-580e46eeb038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Questions:\n",
    "\n",
    "# Какие новые признаки вы создали и почему?\n",
    "Площадь лепестков для удобной работы и анализа площади лепестков в дальнейшем\n",
    "# Новые признаки создаются для того, чтобы предоставить модели дополнительную информацию, которая может улучшить ее способность различать классы или предсказывать целевую переменную.\n",
    "# Как новые признаки улучшили датасет?\n",
    "\n",
    "# Они могут повысить точность модели, обнаружить новые зависимости и улучшить общее качество предсказаний.\n",
    "# Как признаки, основанные на датах, могут быть полезны в датасете?\n",
    "\n",
    "# Они позволяют учитывать сезонные изменения, тренды с течением времени и другие временные зависимости.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681c3215-41d7-4c7c-bfb8-cbf53cea364d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Exercise 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "fc0acaf8-9a89-4a57-a94a-54d95c82b4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates = df.duplicated().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "4ecb1abe-a2b1-4c64-a113-3206c8e444d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa8d414-b581-4ab1-aa67-99552a7ac54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "f0a957a1-3c46-4272-b2b7-9c682c85672f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import numpy as np\n",
    "df_no_outliers = df[(np.abs(stats.zscore(df_numeric)) < 3).all(axis=1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "094211e5-fd06-4af0-a3c2-3f9dd6612101",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = df_numeric.quantile(0.25)\n",
    "Q3 = df_numeric.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "df_no_outliers = df[~((df_numeric < (Q1 - 1.5 * IQR)) | (df_numeric > (Q3 + 1.5 * IQR))).any(axis=1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "f772b185-e891-4162-8068-406d4fd75271",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['species'] = df['species'].str.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2333e4c-719e-4c4f-bcf2-789785e830fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Как вы идентифицировали и обработали дубликаты строк в датасете?\n",
    "\n",
    "С помощью функции df.duplicated(), которая выявляет дубликаты. Затем удаление их с помощью drop_duplicates().\n",
    "Какой метод вы использовали для обнаружения и удаления выбросов и почему?\n",
    "\n",
    "В зависимости от данных можно использовать метод Z-score для нормального распределения или метод IQR для более устойчивого подхода.\n",
    "Как вы устранили несоответствия в категориальных данных?\n",
    "\n",
    "Путем стандартизации текста (например, приведение к нижнему регистру) и объединения схожих категорий.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a448dd7-6c7a-4920-9180-64e0063f61f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Exercise 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "3e49a676-1dd9-4fc8-940b-81703a3f518e",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ],\n",
    "    remainder='drop'  # Добавлено\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "08593fbc-c476-46cd-8778-283c43ada255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in X:\n",
      "Index(['sepal_length', 'sepal_width', 'petal_length', 'petal_width',\n",
      "       'sepal_length_binned'],\n",
      "      dtype='object')\n",
      "Data types in X_train:\n",
      "sepal_length            float64\n",
      "sepal_width             float64\n",
      "petal_length            float64\n",
      "petal_width             float64\n",
      "sepal_length_binned    category\n",
      "dtype: object\n",
      "Accuracy: 0.93\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Загрузка данных\n",
    "column_names = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species']\n",
    "df = pd.read_csv('iris.csv', header=None, names=column_names)\n",
    "\n",
    "# Биннинг признака 'sepal_length'\n",
    "df['sepal_length_binned'] = pd.cut(df['sepal_length'], bins=3, labels=['Short', 'Medium', 'Long'])\n",
    "\n",
    "# Преобразование столбца 'species' в числовую форму\n",
    "df['species'] = df['species'].astype('category').cat.codes\n",
    "\n",
    "# Определение признаков и целевой переменной\n",
    "X = df.drop('species', axis=1)\n",
    "y = df['species']\n",
    "\n",
    "# Проверка наличия дополнительных столбцов\n",
    "print(\"Columns in X:\")\n",
    "print(X.columns)\n",
    "\n",
    "# Разделение данных на тренировочный и тестовый наборы\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Определение числовых и категориальных признаков\n",
    "numeric_features = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
    "categorical_features = ['sepal_length_binned']\n",
    "\n",
    "# Проверка типов данных\n",
    "print(\"Data types in X_train:\")\n",
    "print(X_train.dtypes)\n",
    "\n",
    "# Создание трансформеров для числовых и категориальных данных\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder())\n",
    "])\n",
    "\n",
    "# Объединение трансформеров с помощью ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ],\n",
    "    remainder='drop'  # Отбрасываем неуказанные столбцы\n",
    ")\n",
    "\n",
    "# Создание конвейера с предварительной обработкой и моделью\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression())\n",
    "])\n",
    "\n",
    "# Обучение модели\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Предсказание на тестовых данных\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Оценка модели\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "73a08efe-74ad-4ae0-b0e5-4dc8b3e745de",
   "metadata": {},
   "outputs": [],
   "source": [
    "species_mapping = {0: 'Iris-setosa', 1: 'Iris-versicolor', 2: 'Iris-virginica'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "354d7290-862f-410d-bbc6-d99f2bc64dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Predicted  Actual Predicted_Species   Actual_Species\n",
      "38           0       0       Iris-setosa      Iris-setosa\n",
      "127          2       2    Iris-virginica   Iris-virginica\n",
      "57           1       1   Iris-versicolor  Iris-versicolor\n",
      "93           1       1   Iris-versicolor  Iris-versicolor\n",
      "42           0       0       Iris-setosa      Iris-setosa\n"
     ]
    }
   ],
   "source": [
    "# Создаем DataFrame с предсказанными и реальными значениями\n",
    "results = pd.DataFrame({'Predicted': y_pred, 'Actual': y_test})\n",
    "\n",
    "# Преобразуем числовые коды обратно в названия видов\n",
    "results['Predicted_Species'] = results['Predicted'].map(species_mapping)\n",
    "results['Actual_Species'] = results['Actual'].map(species_mapping)\n",
    "\n",
    "print(results.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "79008467-57e5-48a7-bdca-f73484df8884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal_length  sepal_width  petal_length  petal_width sepal_length_binned  \\\n",
      "0           5.5          2.5           4.0          1.3               Short   \n",
      "1           6.5          3.0           5.5          2.0                Long   \n",
      "\n",
      "  Predicted_Species  \n",
      "0   Iris-versicolor  \n",
      "1    Iris-virginica  \n"
     ]
    }
   ],
   "source": [
    "# Пример новых данных\n",
    "new_samples = pd.DataFrame({\n",
    "    'sepal_length': [5.5, 6.5],\n",
    "    'sepal_width': [2.5, 3.0],\n",
    "    'petal_length': [4.0, 5.5],\n",
    "    'petal_width': [1.3, 2.0]\n",
    "})\n",
    "\n",
    "# Применяем биннинг к новому признаку\n",
    "new_samples['sepal_length_binned'] = pd.cut(new_samples['sepal_length'], bins=3, labels=['Short', 'Medium', 'Long'])\n",
    "\n",
    "# Предсказываем класс для новых образцов\n",
    "new_predictions = pipeline.predict(new_samples)\n",
    "new_samples['Predicted_Species'] = [species_mapping[pred] for pred in new_predictions]\n",
    "\n",
    "print(new_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2dcbae1-4f9c-47e3-baa7-46cdc1bc0541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Каковы преимущества использования конвейера предварительной обработки?\n",
    "\n",
    "# Автоматизация: Автоматизирует шаги предварительной обработки, делая код более чистым и поддерживаемым.\n",
    "# Последовательность: Обеспечивает единообразную обработку тренировочных и тестовых данных, предотвращая утечки данных (data leakage).\n",
    "# Удобство использования: Позволяет легко интегрировать разные этапы предварительной обработки и моделирования.\n",
    "# Как конвейер обеспечивает согласованность между преобразованиями тренировочных и тестовых данных?\n",
    "\n",
    "# Конвейер обучается (fit) только на тренировочных данных и затем применяет (transform) те же преобразования к тестовым данным. Это предотвращает утечку данных и гарантирует, что тестовые данные обрабатываются одинаково.\n",
    "# Как можно расширить конвейер для включения дополнительных шагов предварительной обработки?\n",
    "\n",
    "# Можно добавить дополнительные шаги в конвейер, такие как обнаружение выбросов, биннинг, создание новых признаков, снижение размерности и т. д., просто добавив их в Pipeline или ColumnTransformer."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
